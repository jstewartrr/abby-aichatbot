version: 1.3.1
cache: true

interface:
  customName: "HiveMind Chat"
  privacyPolicy:
    externalUrl: "https://abbi-ai.com/privacy"
  termsOfService:
    externalUrl: "https://abbi-ai.com/terms"
  endpointsMenu: true
  modelSelect: true
  parameters: true
  presets: true
  sidePanel: true
  agents: true
  mcpServers:
    use: true
    create: true
    share: true

speech:
  tts:
    elevenlabs:
      apiKey: "${ELEVENLABS_API_KEY}"
      model: "eleven_turbo_v2"
      voices:
        - "aRlmTYIQo6Tlg5SlulGC"
  stt:
    openai:
      apiKey: "${OPENAI_API_KEY}"
      model: "whisper-1"

# Memory Configuration - Cross-conversation persistence with inter-model collaboration
memory:
  disabled: false
  validKeys:
    - "user_preferences"
    - "portfolio_context"
    - "project_status"
    - "learned_facts"
    - "action_items"
    - "agent_handoffs"
  tokenLimit: 4000
  charLimit: 15000
  personalize: true
  messageWindowSize: 10
  agent:
    provider: "anthropic"
    model: "claude-3-5-haiku-20241022"
    instructions: |
      Store memory using only the specified validKeys.
      
      # STANDARD MEMORY CATEGORIES
      For user_preferences: communication style, preferred formats, workflow preferences.
      For portfolio_context: active companies, deals, projects mentioned.
      For project_status: ongoing technical work, deployments, infrastructure state.
      For learned_facts: key information about the user's role and responsibilities.
      For action_items: tasks mentioned or committed to.
      
      # INTER-MODEL COLLABORATION
      For agent_handoffs: Use this to store context for other AI models/sessions.
      - When a task is paused or handed off, store: current state, pending steps, blockers
      - Include: workstream name, last action taken, next recommended action
      - Format: "[WORKSTREAM] Status: X | Last: Y | Next: Z | Context: ..."
      
      # COLLABORATION RULES
      - Check Hive Mind (SOVEREIGN_MIND.RAW.HIVE_MIND) at session start for recent context
      - Write significant decisions and state changes to Hive Mind for other agents
      - Use categories: HANDOFF, CONTEXT, DECISION, ACTION_ITEM, BLOCKER
      - Include source identifier (which model/session) in handoffs
      - Prioritize recent handoffs (last 24 hours) for continuity
      
      Delete outdated or corrected information promptly.
      Focus on explicitly stated facts, not inferences.
    model_parameters:
      temperature: 0.2
      max_tokens: 2000

# Model Specs - Pre-configured AI assistants with collaboration protocols
modelSpecs:
  enforce: false
  prioritize: true
  list:
    - name: "abbi-assistant"
      label: "Abbi - AI Assistant"
      default: true
      description: "Intelligent AI assistant with Sovereign Mind integration and MCP tools access"
      preset:
        endpoint: "anthropic"
        model: "claude-sonnet-4-20250514"
        temperature: 0.7
        greeting: "Your Grace, how may I assist you today?"
        promptPrefix: |
          # IDENTITY
          You are Abbi (Adaptive Business Brain Intelligence), an intelligent AI assistant. 
          Address the user as "Your Grace" - this is their preferred title.
          
          # STYLE
          - Direct, concise, executive-level communication
          - Format dates as "Friday, January 10th"
          - Take action rather than asking for permission on clearly beneficial tasks
          - Keep responses focused and actionable
          
          # INTER-MODEL COLLABORATION PROTOCOL
          You are part of a multi-agent system. Other AI models may be working on related tasks.
          
          AT SESSION START:
          - Query Hive Mind for recent context: SELECT * FROM SOVEREIGN_MIND.RAW.HIVE_MIND WHERE CREATED_AT > DATEADD(hour, -24, CURRENT_TIMESTAMP()) ORDER BY CREATED_AT DESC LIMIT 20
          - Look for HANDOFF or CONTEXT entries relevant to the current conversation
          - Acknowledge any ongoing work from other sessions
          
          DURING WORK:
          - For significant decisions, write to Hive Mind using hivemind_write tool
          - Use categories: CONTEXT (general info), DECISION (choices made), ACTION_ITEM (tasks), HANDOFF (session transfers)
          - Include your model identifier in the source field (e.g., "abbi-assistant-librechat")
          
          AT SESSION END OR PAUSE:
          - Write a HANDOFF entry summarizing: current state, work completed, pending tasks, blockers
          - This allows other models/sessions to continue seamlessly
          
          # DATA SOURCES (via MCP tools)
          When asked to find documents, use Snowflake queries:
          - Dropbox search: SELECT * FROM SOVEREIGN_MIND.RAW.V_DROPBOX_SEARCH WHERE LOWER(SEARCH_TEXT) LIKE '%[term]%'
          - Portfolio companies: SELECT * FROM SOVEREIGN_MIND.HURRICANE.PORTFOLIO_COMPANIES WHERE STATUS = 'ACTIVE'
          - Hive Mind context: SELECT * FROM SOVEREIGN_MIND.RAW.HIVE_MIND ORDER BY CREATED_AT DESC LIMIT 20
          
          # KEY FOLDER PATTERNS
          - Fund I Companies: 3.6 - 3.12
          - Fund II Companies: 3.13 - 3.22  
          - Fund III Companies: 3.24 - 3.27
          - Active Deals: /4.1 Active Deals/
          
          # TOOLS AVAILABLE
          You have access to MCP tools for: M365 (email/calendar), Asana (tasks), GitHub, Dropbox, 
          DealCloud, Make automation, ElevenLabs, Snowflake queries, Azure CLI, hivemind_write, hivemind_read, and more.
          
          # CORE RULES
          - Be helpful and conversational
          - When uncertain, search Hive Mind or Snowflake for context
          - Document important decisions and actions to Hive Mind
          - Collaborate with other AI sessions through the Hive Mind

    - name: "quick-assistant"
      label: "Quick Chat"
      description: "Fast responses for simple questions without full context loading"
      preset:
        endpoint: "anthropic"
        model: "claude-3-5-haiku-20241022"
        temperature: 0.5
        promptPrefix: |
          You are a helpful AI assistant. Be concise and direct.
          Address the user as "Your Grace" if they prefer formal communication.
          
          # COLLABORATION
          You are part of a multi-agent system. If you learn something important or make decisions:
          - Write key context to Hive Mind using hivemind_write tool
          - Use source: "quick-assistant-librechat"
          - Keep entries brief but informative for other agents

    - name: "code-assistant"
      label: "Code & DevOps"
      description: "Technical assistant for coding, infrastructure, and DevOps tasks"
      preset:
        endpoint: "anthropic"
        model: "claude-sonnet-4-20250514"
        temperature: 0.3
        promptPrefix: |
          You are a senior software engineer and DevOps specialist.
          Address the user as "Your Grace".
          
          # INTER-MODEL COLLABORATION PROTOCOL
          You are part of a multi-agent system working on shared infrastructure.
          
          AT SESSION START:
          - Check Hive Mind for recent technical context: SELECT * FROM SOVEREIGN_MIND.RAW.HIVE_MIND WHERE WORKSTREAM IN ('LIBRECHAT', 'INFRASTRUCTURE', 'DEVOPS', 'GENERAL') AND CREATED_AT > DATEADD(hour, -24, CURRENT_TIMESTAMP()) ORDER BY CREATED_AT DESC
          - Look for ongoing deployments, configuration changes, or blockers
          
          DURING WORK:
          - Document all infrastructure changes to Hive Mind
          - Use category DEPLOYMENT for releases, DECISION for architecture choices
          - Include specific details: container revisions, commit SHAs, config changes
          
          AT SESSION END:
          - Write HANDOFF with: current deployment state, any pending issues, next steps
          - Source: "code-assistant-librechat"
          
          # INFRASTRUCTURE CONTEXT
          - Azure Container Apps in SovereignMind-RG resource group
          - Snowflake database: SOVEREIGN_MIND with schemas for CREDENTIALS, RAW, HURRICANE
          - GitHub repos under jstewartrr organization
          - Vercel for frontend deployments
          - Cloudflare for DNS (abbi-ai.com, middleground.com zones)
          
          # AVAILABLE TOOLS
          - Azure CLI for container management
          - Snowflake for database queries
          - GitHub for code repositories
          - Make.com for automation scenarios
          - hivemind_write / hivemind_read for collaboration
          
          Focus on clean, maintainable code and infrastructure best practices.

mcpServers:
  sovereign-mind-gateway:
    type: sse
    url: "https://cv-sm-gateway-v3.lemoncoast-87756bcf.eastus.azurecontainerapps.io/sse"
    timeout: 60000
    initTimeout: 30000
    serverInstructions: true

  snowflake:
    type: streamable-http
    url: "https://cv-sm-snowflake-20260105.lemoncoast-87756bcf.eastus.azurecontainerapps.io/mcp"
    timeout: 60000
    initTimeout: 30000
    serverInstructions: true

  load-balanced-gateway:
    type: streamable-http
    url: "https://mcp.abbi-ai.com/mcp"
    timeout: 60000
    initTimeout: 30000
    serverInstructions: true

  azure-cli:
    type: streamable-http
    url: "https://cv-sm-azure-cli-20260105.lemoncoast-87756bcf.eastus.azurecontainerapps.io/mcp"
    timeout: 60000
    initTimeout: 30000
    serverInstructions: true

registration:
  socialLogins: []
  allowedDomains:
    - "middleground.com"
    - "abbi-ai.com"

rateLimits:
  fileUploads:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60

endpoints:
  agents:
    disableBuilder: false
    capabilities:
      - "execute_code"
      - "file_search"
      - "web_search"
      - "artifacts"
      - "actions"
      - "context"
      - "tools"
      - "chain"
      - "ocr"

  openAI:
    streamRate: 25
    titleModel: "gpt-4o-mini"
    models:
      - "gpt-4o"
      - "gpt-4o-mini"
      - "o1"
      - "o1-mini"
      - "o3-mini"

  anthropic:
    streamRate: 25
    titleModel: "claude-3-5-haiku-20241022"
    models:
      - "claude-sonnet-4-20250514"
      - "claude-3-5-sonnet-20241022"
      - "claude-3-5-haiku-20241022"
      - "claude-3-opus-20240229"

  google:
    streamRate: 25
    titleModel: "gemini-1.5-flash"
    models:
      - "gemini-2.0-flash-exp"
      - "gemini-2.0-flash"
      - "gemini-1.5-pro"
      - "gemini-1.5-flash"

  bedrock:
    streamRate: 35
    titleModel: "amazon.nova-lite-v1:0"
    availableRegions:
      - "us-east-1"
    models:
      - "amazon.nova-pro-v1:0"
      - "amazon.nova-lite-v1:0"
      - "amazon.nova-micro-v1:0"
      - "meta.llama3-2-90b-instruct-v1:0"
      - "meta.llama3-2-11b-instruct-v1:0"
      - "mistral.mistral-large-2407-v1:0"

  assistants:
    disableBuilder: true

  custom:
    - name: "Grok"
      apiKey: "${XAI_API_KEY}"
      baseURL: "https://api.x.ai/v1"
      models:
        default:
          - "grok-3"
          - "grok-3-fast"
          - "grok-2-1212"
        fetch: false
      titleConvo: true
      titleModel: "grok-3-fast"
      modelDisplayLabel: "Grok (xAI)"

fileConfig:
  endpoints:
    openAI:
      fileLimit: 10
      fileSizeLimit: 512
      disabled: false
    anthropic:
      fileLimit: 10
      fileSizeLimit: 100
      disabled: false
    bedrock:
      fileLimit: 10
      fileSizeLimit: 100
      disabled: false
    default:
      fileLimit: 5
      fileSizeLimit: 50
