version: 1.3.1
cache: true

interface:
  customName: "HiveMind Chat"
  privacyPolicy:
    externalUrl: "https://abbi-ai.com/privacy"
  termsOfService:
    externalUrl: "https://abbi-ai.com/terms"
  endpointsMenu: true
  modelSelect: true
  parameters: true
  presets: true
  sidePanel: true
  mcpServers:
    use: true
    create: true
    share: true

# MCP Server Configuration - Using SSE transport
mcpServers:
  sovereign-mind-gateway:
    type: sse
    url: "https://cv-sm-gateway-v3.lemoncoast-87756bcf.eastus.azurecontainerapps.io/sse"
    timeout: 60000
    initTimeout: 30000
    serverInstructions: true
  
  sovereign-mind-snowflake:
    type: sse
    url: "https://cv-sm-snowflake-20260105.lemoncoast-87756bcf.eastus.azurecontainerapps.io/sse"
    timeout: 60000
    initTimeout: 30000
    serverInstructions: true
  
  sovereign-mind-azure:
    type: sse
    url: "https://cv-sm-azure-cli-20260105.lemoncoast-87756bcf.eastus.azurecontainerapps.io/sse"
    timeout: 60000
    initTimeout: 30000
    serverInstructions: true

registration:
  socialLogins: []
  allowedDomains:
    - "middleground.com"
    - "abbi-ai.com"

rateLimits:
  fileUploads:
    ipMax: 100
    ipWindowInMinutes: 60
    userMax: 50
    userWindowInMinutes: 60

# Endpoint Configuration
endpoints:
  # Agents Configuration
  agents:
    disableBuilder: false
    capabilities:
      - "execute_code"
      - "file_search"
      - "web_search"
      - "artifacts"
      - "actions"
      - "context"
      - "tools"
      - "chain"
      - "ocr"

  # Built-in OpenAI - models as array
  openAI:
    models: ["gpt-4o", "gpt-4o-mini", "o1", "o1-mini", "o3-mini"]
    titleModel: "gpt-4o-mini"

  # Built-in Anthropic - models as array
  anthropic:
    models: ["claude-sonnet-4-20250514", "claude-opus-4-20250514", "claude-3-5-haiku-20241022"]
    titleModel: "claude-sonnet-4-20250514"

  # Built-in Google/Gemini - models as array
  google:
    models: ["gemini-2.0-flash-exp", "gemini-1.5-pro", "gemini-1.5-flash"]
    titleModel: "gemini-2.0-flash-exp"

  # Built-in Bedrock - models as array
  bedrock:
    titleModel: "anthropic.claude-3-haiku-20240307-v1:0"
    streamRate: 35
    availableRegions:
      - "us-east-1"
    models:
      - "anthropic.claude-sonnet-4-5-20250929-v1:0"
      - "anthropic.claude-haiku-4-5-20251001-v1:0"
      - "anthropic.claude-opus-4-1-20250805-v1:0"
      - "anthropic.claude-3-5-sonnet-20241022-v2:0"
      - "anthropic.claude-3-haiku-20240307-v1:0"
      - "meta.llama3-1-70b-instruct-v1:0"
      - "meta.llama3-1-8b-instruct-v1:0"
      - "amazon.titan-text-premier-v1:0"
      - "mistral.mistral-large-2407-v1:0"

  # Disable assistants
  assistants:
    disabled: true

  # Custom Endpoints - ONLY for providers without built-in support
  custom:
    # Grok via xAI (no built-in endpoint exists)
    - name: "Grok"
      apiKey: "${XAI_API_KEY}"
      baseURL: "https://api.x.ai/v1"
      models:
        default: ["grok-2-latest", "grok-2-vision-1212", "grok-beta"]
        fetch: false
      titleConvo: true
      titleModel: "grok-2-latest"
      modelDisplayLabel: "Grok (xAI)"

# File Configuration
fileConfig:
  endpoints:
    openAI:
      fileLimit: 10
      fileSizeLimit: 512
      disabled: false
    anthropic:
      fileLimit: 10
      fileSizeLimit: 100
      disabled: false
    default:
      fileLimit: 5
      fileSizeLimit: 50
